{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Set: \n",
    "https://github.com/mhjabreel/CharCnn_Keras/tree/master/data/ag_news_csv\n",
    "\n",
    "The AG's news topic classification dataset is constructed by choosing the 4 largest classes from the original corpus. Each class contains 30,000 training samples and 1,900 testing samples. The total number of training samples is 120,000 and testing 7,600. \n",
    "\n",
    "The classes are: \n",
    "\n",
    "* World\n",
    "* Sports\n",
    "* Business\n",
    "* Science/Technology\n",
    "\n",
    "#### For more information on how to use Lbl2Vec, visit the [API Guide](https://lbl2vec.readthedocs.io/en/latest/api.html#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quoc Anh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-08-06 18:03:24,973\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "from lbl2vec import Lbl2Vec\n",
    "import pandas as pd\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.parsing.preprocessing import strip_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train data\n",
    "ag_train = pd.read_csv('data/train.csv',sep=',',header=None, names=['class','title','description'])\n",
    "\n",
    "# load test data\n",
    "ag_test = pd.read_csv('data/test.csv',sep=',',header=None, names=['class','title','description'])\n",
    "\n",
    "# load labels with keywords\n",
    "labels = pd.read_csv('data/labels.csv',sep=';')\n",
    "\n",
    "# split keywords by separator and save them as array\n",
    "labels['keywords'] = labels['keywords'].apply(lambda x: x.split(' '))\n",
    "\n",
    "# convert description keywords to lowercase\n",
    "labels['keywords'] = labels['keywords'].apply(lambda description_keywords: [keyword.lower() for keyword in description_keywords])\n",
    "\n",
    "# get number of keywords for each class\n",
    "labels['number_of_keywords'] = labels['keywords'].apply(lambda row: len(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_index</th>\n",
       "      <th>class_name</th>\n",
       "      <th>keywords</th>\n",
       "      <th>number_of_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>World</td>\n",
       "      <td>[election, state, president, police, politics,...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Sports</td>\n",
       "      <td>[olympic, football, sport, league, baseball, r...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Business</td>\n",
       "      <td>[company, market, oil, consumers, exchange, bu...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Science/Technology</td>\n",
       "      <td>[laboratory, computers, science, technology, w...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class_index          class_name  \\\n",
       "0            1               World   \n",
       "1            2              Sports   \n",
       "2            3            Business   \n",
       "3            4  Science/Technology   \n",
       "\n",
       "                                            keywords  number_of_keywords  \n",
       "0  [election, state, president, police, politics,...                  11  \n",
       "1  [olympic, football, sport, league, baseball, r...                  32  \n",
       "2  [company, market, oil, consumers, exchange, bu...                  10  \n",
       "3  [laboratory, computers, science, technology, w...                  18  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc: document text string\n",
    "# returns tokenized document\n",
    "# strip_tags removes meta tags from the text\n",
    "# simple preprocess converts a document into a list of lowercase tokens, ignoring tokens that are too short or too long \n",
    "# simple preprocess also removes numerical values as well as punktuation characters\n",
    "def tokenize(doc):\n",
    "    return simple_preprocess(strip_tags(doc), deacc=True, min_len=2, max_len=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add data set type column\n",
    "ag_train['data_set_type'] = 'train'\n",
    "ag_test['data_set_type'] = 'test'\n",
    "\n",
    "# concat train and test data\n",
    "ag_full_corpus = pd.concat([ag_train,ag_test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize and tag documents combined title + description for Lbl2Vec training\n",
    "ag_full_corpus['tagged_docs'] = ag_full_corpus.apply(lambda row: TaggedDocument(tokenize(row['title'] + '. ' + row['description']), [str(row.name)]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add doc_key column\n",
    "ag_full_corpus['doc_key'] = ag_full_corpus.index.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add class_name column\n",
    "ag_full_corpus = ag_full_corpus.merge(labels, left_on='class', right_on='class_index', how='left').drop(['class', 'keywords'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>data_set_type</th>\n",
       "      <th>tagged_docs</th>\n",
       "      <th>doc_key</th>\n",
       "      <th>class_index</th>\n",
       "      <th>class_name</th>\n",
       "      <th>number_of_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "      <td>train</td>\n",
       "      <td>([wall, st, bears, claw, back, into, the, blac...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Business</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "      <td>train</td>\n",
       "      <td>([carlyle, looks, toward, commercial, aerospac...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Business</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "      <td>train</td>\n",
       "      <td>([oil, and, economy, cloud, stocks, outlook, r...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Business</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "      <td>train</td>\n",
       "      <td>([iraq, halts, oil, exports, from, main, south...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Business</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "      <td>train</td>\n",
       "      <td>([oil, prices, soar, to, all, time, record, po...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Business</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Wall St. Bears Claw Back Into the Black (Reuters)   \n",
       "1  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
       "2    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
       "3  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
       "4  Oil prices soar to all-time record, posing new...   \n",
       "\n",
       "                                         description data_set_type  \\\n",
       "0  Reuters - Short-sellers, Wall Street's dwindli...         train   \n",
       "1  Reuters - Private investment firm Carlyle Grou...         train   \n",
       "2  Reuters - Soaring crude prices plus worries\\ab...         train   \n",
       "3  Reuters - Authorities have halted oil export\\f...         train   \n",
       "4  AFP - Tearaway world oil prices, toppling reco...         train   \n",
       "\n",
       "                                         tagged_docs doc_key  class_index  \\\n",
       "0  ([wall, st, bears, claw, back, into, the, blac...       0            3   \n",
       "1  ([carlyle, looks, toward, commercial, aerospac...       1            3   \n",
       "2  ([oil, and, economy, cloud, stocks, outlook, r...       2            3   \n",
       "3  ([iraq, halts, oil, exports, from, main, south...       3            3   \n",
       "4  ([oil, prices, soar, to, all, time, record, po...       4            3   \n",
       "\n",
       "  class_name  number_of_keywords  \n",
       "0   Business                  10  \n",
       "1   Business                  10  \n",
       "2   Business                  10  \n",
       "3   Business                  10  \n",
       "4   Business                  10  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ag_full_corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Lbl2Vec\n",
    "\n",
    "Train a new model from scratch with the following parameters:\n",
    "* keywords_list : iterable list of lists with descriptive keywords for each topic.\n",
    "* tagged_documents : iterable list of [gensim.models.doc2vec.TaggedDocument](https://radimrehurek.com/gensim/models/doc2vec.html#gensim.models.doc2vec.TaggedDocument) elements. Each element consists of one document.\n",
    "* label_names : iterable list of custom names for each label. Label names and keywords of the same topic must have the same index.\n",
    "* similarity_threshold : only documents with a higher similarity to the respective description keywords than this treshold are used to calculate the label embedding.\n",
    "* min_num_docs : minimum number of documents that are used to calculate the label embedding. \n",
    "* epochs : number of iterations over the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model with parameters\n",
    "lbl2vec_model = Lbl2Vec(keywords_list=list(labels['keywords']), tagged_documents=ag_full_corpus['tagged_docs'], label_names=list(labels['class_name']), similarity_threshold=0.30, min_num_docs=100, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-06 18:04:22,106 - Lbl2Vec - INFO - Train document and word embeddings\n",
      "2023-08-06 18:09:03,734 - Lbl2Vec - INFO - Train label embeddings\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "lbl2vec_model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict document topics of documents used to train Lbl2Vec\n",
    "\n",
    "Compute similarity scores of learned document vectors from documents that were used to train the model to each of the learned label vectors. The similarity scores consist of cosine similarities and therefore have a value range of [-1,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-06 18:09:21,864 - Lbl2Vec - INFO - Get document embeddings from model\n",
      "2023-08-06 18:09:22,007 - Lbl2Vec - INFO - Calculate document<->label similarities\n"
     ]
    }
   ],
   "source": [
    "# predict similarity scores\n",
    "model_docs_lbl_similarities = lbl2vec_model.predict_model_docs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_key</th>\n",
       "      <th>most_similar_label</th>\n",
       "      <th>highest_similarity_score</th>\n",
       "      <th>World</th>\n",
       "      <th>Sports</th>\n",
       "      <th>Business</th>\n",
       "      <th>Science/Technology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Science/Technology</td>\n",
       "      <td>0.471337</td>\n",
       "      <td>0.240753</td>\n",
       "      <td>0.410054</td>\n",
       "      <td>0.421352</td>\n",
       "      <td>0.471337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Business</td>\n",
       "      <td>0.435966</td>\n",
       "      <td>0.284427</td>\n",
       "      <td>0.320331</td>\n",
       "      <td>0.435966</td>\n",
       "      <td>0.414551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Business</td>\n",
       "      <td>0.537299</td>\n",
       "      <td>0.214300</td>\n",
       "      <td>0.296246</td>\n",
       "      <td>0.537299</td>\n",
       "      <td>0.460700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>World</td>\n",
       "      <td>0.489334</td>\n",
       "      <td>0.489334</td>\n",
       "      <td>0.129425</td>\n",
       "      <td>0.391338</td>\n",
       "      <td>0.293481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Business</td>\n",
       "      <td>0.436432</td>\n",
       "      <td>0.379450</td>\n",
       "      <td>0.332522</td>\n",
       "      <td>0.436432</td>\n",
       "      <td>0.409892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc_key  most_similar_label  highest_similarity_score     World    Sports  \\\n",
       "0       0  Science/Technology                  0.471337  0.240753  0.410054   \n",
       "1       1            Business                  0.435966  0.284427  0.320331   \n",
       "2       2            Business                  0.537299  0.214300  0.296246   \n",
       "3       3               World                  0.489334  0.489334  0.129425   \n",
       "4       4            Business                  0.436432  0.379450  0.332522   \n",
       "\n",
       "   Business  Science/Technology  \n",
       "0  0.421352            0.471337  \n",
       "1  0.435966            0.414551  \n",
       "2  0.537299            0.460700  \n",
       "3  0.391338            0.293481  \n",
       "4  0.436432            0.409892  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_docs_lbl_similarities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add label thresholds\n",
    "\n",
    "Add thresholds for each topic/label. This provides the possibility to select only the documents whose similarity between topic and label is higher than the manually defined thresholds. This way, only confident predictions can be filtered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually define thresholds for each label\n",
    "threshold_tpls = [('World', 0.3), ('Sports', 0.35), ('Business', 0.25), ('Science/Technology', 0.2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the label thresholds to the predicted similarities\n",
    "threshold_sims = lbl2vec_model.add_lbl_thresholds(lbl_similarities_df=model_docs_lbl_similarities, lbl_thresholds=threshold_tpls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_key</th>\n",
       "      <th>most_similar_label</th>\n",
       "      <th>highest_similarity_score</th>\n",
       "      <th>lbl_threshold</th>\n",
       "      <th>World</th>\n",
       "      <th>Sports</th>\n",
       "      <th>Business</th>\n",
       "      <th>Science/Technology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Science/Technology</td>\n",
       "      <td>0.471337</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.240753</td>\n",
       "      <td>0.410054</td>\n",
       "      <td>0.421352</td>\n",
       "      <td>0.471337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Business</td>\n",
       "      <td>0.435966</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.284427</td>\n",
       "      <td>0.320331</td>\n",
       "      <td>0.435966</td>\n",
       "      <td>0.414551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Business</td>\n",
       "      <td>0.537299</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.214300</td>\n",
       "      <td>0.296246</td>\n",
       "      <td>0.537299</td>\n",
       "      <td>0.460700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>World</td>\n",
       "      <td>0.489334</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.489334</td>\n",
       "      <td>0.129425</td>\n",
       "      <td>0.391338</td>\n",
       "      <td>0.293481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Business</td>\n",
       "      <td>0.436432</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.379450</td>\n",
       "      <td>0.332522</td>\n",
       "      <td>0.436432</td>\n",
       "      <td>0.409892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc_key  most_similar_label  highest_similarity_score  lbl_threshold  \\\n",
       "0       0  Science/Technology                  0.471337           0.20   \n",
       "1       1            Business                  0.435966           0.25   \n",
       "2       2            Business                  0.537299           0.25   \n",
       "3       3               World                  0.489334           0.30   \n",
       "4       4            Business                  0.436432           0.25   \n",
       "\n",
       "      World    Sports  Business  Science/Technology  \n",
       "0  0.240753  0.410054  0.421352            0.471337  \n",
       "1  0.284427  0.320331  0.435966            0.414551  \n",
       "2  0.214300  0.296246  0.537299            0.460700  \n",
       "3  0.489334  0.129425  0.391338            0.293481  \n",
       "4  0.379450  0.332522  0.436432            0.409892  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold_sims.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get only the documents that have a higher similarity to their most similar label \n",
    "# than the respective defined threshold\n",
    "threshold_sims = threshold_sims[threshold_sims['highest_similarity_score'] > threshold_sims['lbl_threshold']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
